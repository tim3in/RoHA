/* Generated by Edge Impulse
*
* Permission is hereby granted, free of charge, to any person obtaining a copy
* of this software and associated documentation files (the "Software"), to deal
* in the Software without restriction, including without limitation the rights
* to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
* copies of the Software, and to permit persons to whom the Software is
* furnished to do so, subject to the following conditions:
*
* The above copyright notice and this permission notice shall be included in
* all copies or substantial portions of the Software.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
* AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
* OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
* SOFTWARE.
*/
// Generated on: 09.07.2021 06:55:45

#include <stdio.h>
#include <stdlib.h>
#include <vector>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/kernels/micro_ops.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

namespace {

constexpr int kTensorArenaSize = 8512;

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_AVERAGE_POOL_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

TfLiteContext ctx{};
TfLiteTensor tflTensors[17];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[8];

const TfArray<2, int> tensor_dimension0 = { 2, { 1,650 } };
const TfArray<1, float> quant0_scale = { 1, { 0.034759312868118286, } };
const TfArray<1, int> quant0_zero = { 1, { 7 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(8) int32_t tensor_data1[2] = { -1, 260, };
const TfArray<1, int> tensor_dimension1 = { 1, { 2 } };
const ALIGN(8) int32_t tensor_data2[10] = { 116, 277, -539, -351, 240, -230, -1357, -736, -192, -266, };
const TfArray<1, int> tensor_dimension2 = { 1, { 10 } };
const TfArray<10, float> quant2_scale = { 10, { 0.00010113645839737728, 7.5333700806368142e-05, 6.6087042796425521e-05, 7.3171548137906939e-05, 9.0085872216150165e-05, 7.4387338827364147e-05, 6.1557642766274512e-05, 6.3065162976272404e-05, 5.9683799918275326e-05, 6.5472435380797833e-05, } };
const TfArray<10, int> quant2_zero = { 10, { 0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant2 = { (TfLiteFloatArray*)&quant2_scale, (TfLiteIntArray*)&quant2_zero, 0 };
const ALIGN(8) int32_t tensor_data3[5] = { -1025, -148, 57, 513, -597, };
const TfArray<1, int> tensor_dimension3 = { 1, { 5 } };
const TfArray<5, float> quant3_scale = { 5, { 3.0801660614088178e-05, 4.4605163566302508e-05, 5.583215897786431e-05, 4.3827967601828277e-05, 3.011584522027988e-05, } };
const TfArray<5, int> quant3_zero = { 5, { 0,0,0,0,0 } };
const TfLiteAffineQuantization quant3 = { (TfLiteFloatArray*)&quant3_scale, (TfLiteIntArray*)&quant3_zero, 0 };
const ALIGN(8) int32_t tensor_data4[2] = { -944, 944, };
const TfArray<1, int> tensor_dimension4 = { 1, { 2 } };
const TfArray<1, float> quant4_scale = { 1, { 4.0315302612725645e-05, } };
const TfArray<1, int> quant4_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant4 = { (TfLiteFloatArray*)&quant4_scale, (TfLiteIntArray*)&quant4_zero, 0 };
const ALIGN(8) int32_t tensor_data5[4] = { 1, 50, 13, 1, };
const TfArray<1, int> tensor_dimension5 = { 1, { 4 } };
const ALIGN(8) int8_t tensor_data6[2*260] = { 
  -12, -89, -14, -127, -10, -24, 6, 40, 8, 28, -11, 22, -71, 21, 10, -13, -2, 9, -7, -31, 20, 51, -43, 14, -34, -35, 47, -38, 5, 49, 13, 81, 46, 39, -30, -57, 16, -72, 64, 39, -39, 5, -19, -7, -33, -32, 65, 22, -4, -43, 54, 24, 70, 14, -24, -9, 16, -76, 18, 30, 19, -14, -6, 85, 6, -1, -9, -31, 30, -47, -22, 107, -51, -77, -41, 19, 3, 43, 2, -44, -21, -3, 32, 31, -45, -8, 10, -8, 17, -39, -56, -20, -73, -8, 7, 63, 39, 17, 75, 19, 2, -54, 96, -20, 13, 2, -8, 33, -59, 16, -35, -27, 41, 20, -11, 37, -82, -54, -92, -33, -2, -31, -26, 41, 5, 36, 30, 71, -4, -45, 10, 8, 50, 5, 35, 37, -4, -41, 18, 21, 15, 51, 14, 25, -34, -58, 36, 23, -28, 18, -36, 9, 26, -54, 12, 57, 1, 10, 54, -33, -12, 32, 28, -11, -19, -34, -34, 53, -44, -21, 9, -12, -33, 13, 57, -27, 27, 43, -25, -5, -39, 10, 54, -25, -32, 59, 6, 5, -50, 4, -1, 44, -54, -33, -28, -10, 66, 55, 47, 9, 21, -38, -51, 23, -17, -21, -46, 21, 66, -46, 29, 26, -65, -10, -9, 49, -21, -42, 42, -37, -28, 51, 28, 76, 34, -43, 31, -12, 62, 44, 7, -23, 15, 72, -34, -2, -2, -46, 54, 54, -9, -22, 6, 51, -9, 33, -13, -65, -118, 53, -4, -31, -35, 25, 23, -4, 26, -4, -14, 31, 
  29, -23, 4, 123, 61, 17, 49, -5, 6, -8, 15, -4, 68, -18, -32, -50, 45, -49, 76, 39, -49, -32, 8, -33, -50, 2, 58, -1, 7, -21, 7, -9, -53, -27, 40, 8, -11, 8, -23, -60, -26, 41, 44, 85, -3, -26, -22, 7, 49, 48, -17, 27, -65, -15, 3, 65, 20, -3, 47, -35, -17, -74, 12, -50, -40, 33, -12, -84, -40, -5, 68, -63, 45, -15, -5, -14, -34, -15, -51, 20, -30, 24, 35, -79, 7, -27, 65, -23, -71, -40, 48, -63, 49, 33, 3, -59, -4, 51, 21, -7, -8, 50, -13, 15, 43, 15, 5, -21, -15, -44, 53, 27, -16, -60, 21, -47, 41, -36, 93, 66, 53, 36, 44, 11, -28, -69, -2, -77, -4, 41, 9, 54, -17, -36, -41, -2, 96, 40, 47, 14, -18, 14, -12, -26, 46, 2, 10, 59, 81, -42, 32, -42, 40, 79, 51, -38, 35, -33, -12, -55, 8, 13, 44, 51, 51, 17, 31, 15, -54, -53, 56, -22, -59, 26, 38, -25, 27, 12, 30, 52, -52, -38, 8, 31, -73, 22, 0, 35, 37, 17, -35, -44, 55, 37, -21, -50, 17, -88, -33, -30, 59, -3, 68, 15, 47, 26, 52, 28, 16, 3, 29, -43, 40, -48, 17, -35, -75, 71, -70, 2, 60, -68, -69, -75, 2, 37, 16, 65, 39, 30, 11, -17, -5, 2, 24, -34, 18, -45, 15, 5, -45, 39, 26, 17, -43, -27, -60, 60, 116, 25, 31, -31, 43, -14, -2, -24, 70, 20, 98, 5, 
};
const TfArray<2, int> tensor_dimension6 = { 2, { 2,260 } };
const TfArray<1, float> quant6_scale = { 1, { 0.0025338029954582453, } };
const TfArray<1, int> quant6_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(8) int8_t tensor_data7[10*5*5*1] = { 
  /* [0][0][][] */ -29, -68, -54, -27, -3, 
  /* [0][1][][] */ -45, -20, -45, 11, 65, 
  /* [0][2][][] */ -23, -39, -43, 70, -2, 
  /* [0][3][][] */ -51, -64, -4, 59, 64, 
  /* [0][4][][] */ -3, -41, -27, 127, 6, 
  /* [1][0][][] */ 13, 26, 55, 92, 1, 
  /* [1][1][][] */ 4, -66, 2, 17, -33, 
  /* [1][2][][] */ 127, 51, 56, 2, 10, 
  /* [1][3][][] */ 45, -75, 14, 45, 58, 
  /* [1][4][][] */ 35, -71, -84, 41, -27, 
  /* [2][0][][] */ 14, 29, -127, -28, -75, 
  /* [2][1][][] */ 9, 56, -61, -40, -8, 
  /* [2][2][][] */ 44, 32, -85, 24, -31, 
  /* [2][3][][] */ -36, -15, -22, -32, 48, 
  /* [2][4][][] */ -59, 29, -47, -74, -18, 
  /* [3][0][][] */ -68, 108, -12, 30, -114, 
  /* [3][1][][] */ -38, 101, 47, -34, 21, 
  /* [3][2][][] */ 39, 46, -57, -21, 37, 
  /* [3][3][][] */ -30, 36, 52, 18, 127, 
  /* [3][4][][] */ -2, 77, -67, 12, 52, 
  /* [4][0][][] */ 43, 3, -29, -112, -85, 
  /* [4][1][][] */ 76, 36, -104, -40, 7, 
  /* [4][2][][] */ 81, -21, -127, -38, -5, 
  /* [4][3][][] */ 80, 17, -66, -29, 5, 
  /* [4][4][][] */ 75, -44, -78, -56, 19, 
  /* [5][0][][] */ 51, -6, -6, 126, -17, 
  /* [5][1][][] */ -22, -57, 45, 55, -10, 
  /* [5][2][][] */ -24, 11, 7, -1, 48, 
  /* [5][3][][] */ -105, -48, -19, -8, 127, 
  /* [5][4][][] */ -63, -76, -63, 97, 96, 
  /* [6][0][][] */ -27, -29, 64, 127, 40, 
  /* [6][1][][] */ -7, 28, 37, 16, 10, 
  /* [6][2][][] */ 37, 40, -30, 13, 45, 
  /* [6][3][][] */ -42, -24, -9, 94, 52, 
  /* [6][4][][] */ -39, -20, -102, -11, -70, 
  /* [7][0][][] */ -58, -48, 63, 49, 13, 
  /* [7][1][][] */ -18, -19, -63, -5, 80, 
  /* [7][2][][] */ 110, -22, -17, 89, -62, 
  /* [7][3][][] */ 127, 93, -127, -54, -30, 
  /* [7][4][][] */ 108, 4, -114, 43, -95, 
  /* [8][0][][] */ 41, -58, 8, -80, 109, 
  /* [8][1][][] */ 51, -57, 127, 70, 96, 
  /* [8][2][][] */ -17, 44, -6, -54, -6, 
  /* [8][3][][] */ -83, 49, -2, -111, -2, 
  /* [8][4][][] */ -86, -75, 117, -109, 21, 
  /* [9][0][][] */ 21, 63, 37, 102, 17, 
  /* [9][1][][] */ 67, 127, 49, -95, -18, 
  /* [9][2][][] */ 2, 18, 2, -12, -35, 
  /* [9][3][][] */ -95, 30, 62, -63, 44, 
  /* [9][4][][] */ 34, -12, -96, 34, -38, 
};
const TfArray<4, int> tensor_dimension7 = { 4, { 10,5,5,1 } };
const TfArray<10, float> quant7_scale = { 10, { 0.0029096219222992659, 0.0021672954317182302, 0.0019012759439647198, 0.0021050919312983751, 0.0025917047169059515, 0.002140069380402565, 0.0017709684325382113, 0.0018143384950235486, 0.0017170592909678817, 0.001883594086393714, } };
const TfArray<10, int> quant7_zero = { 10, { 0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(8) int8_t tensor_data8[5*5*5*10] = { 
  /* [0][0][][] */ -75,56,-1,72,29,-77,4,3,37,-51, -51,-34,-2,-12,13,-36,-74,62,-73,-100, -71,-126,-84,75,40,-91,58,21,-9,-94, -31,77,-127,-77,-24,-35,-60,-127,-10,53, 27,26,-87,32,-93,-46,-54,-19,-72,-65, 
  /* [0][1][][] */ -82,15,90,-96,-42,-90,-107,-74,-67,-99, -63,68,-76,62,-2,57,-28,-67,80,-30, 14,51,52,29,-16,58,30,60,1,-45, -56,55,40,20,-119,15,65,65,-79,-10, 2,43,10,-17,-15,43,-100,-23,-112,-8, 
  /* [0][2][][] */ -84,-61,8,-9,87,-42,-59,56,-41,67, -68,82,-14,-36,-44,-52,75,-56,-52,-3, 22,60,-84,-10,-91,-84,-111,-104,-100,-79, -114,8,-109,-51,75,-39,-39,-1,73,52, -2,-52,-40,-18,45,-10,-111,52,-37,-115, 
  /* [0][3][][] */ 44,18,22,-18,24,73,-30,8,-3,-121, -85,-11,-69,5,-6,-8,92,-93,-79,-20, 55,-104,-4,-84,-7,-2,47,-24,31,31, 13,-79,45,54,35,-42,-21,-42,-31,-25, -55,-40,-28,48,-113,16,-69,-47,-109,77, 
  /* [0][4][][] */ -79,22,-27,-47,-40,-59,-2,-51,-2,-26, 27,-48,89,-98,58,-90,-6,-44,-66,-15, -57,-11,22,28,17,49,-101,57,-86,-40, -71,11,7,-59,-99,-82,-3,41,89,-60, 27,-48,7,15,20,-65,-58,-44,-10,-1, 
  /* [1][0][][] */ -49,61,26,-25,-20,22,55,55,27,75, 15,-5,53,33,-53,66,-8,-20,-67,75, -23,-11,-92,32,-49,-65,-32,-24,-51,13, -40,5,-57,13,22,-15,13,38,-69,-60, 24,57,43,56,-24,-73,27,33,-28,-41, 
  /* [1][1][][] */ 67,12,10,-22,64,-39,-3,22,61,15, -25,-62,-8,-31,-15,68,53,0,10,-25, -9,-33,-21,9,-59,44,-39,13,21,-14, -69,17,-28,-32,7,52,10,-17,52,-13, 23,33,-14,69,40,31,12,40,-36,60, 
  /* [1][2][][] */ 66,-27,11,-85,6,-35,57,-68,26,-90, 69,28,-11,38,-34,-2,17,-47,-14,24, 64,-40,-5,-32,-49,8,-24,14,-15,-58, 1,18,11,36,-64,-25,-29,-50,36,41, -62,6,60,-13,-54,44,26,41,42,30, 
  /* [1][3][][] */ 69,-59,50,-44,-71,51,25,17,81,-127, 47,-5,-19,68,18,90,6,-111,10,-10, 52,-34,2,57,-54,-15,-34,73,-78,22, -35,38,29,12,-8,15,20,36,-31,49, 83,25,27,-101,-12,-12,12,33,-32,-46, 
  /* [1][4][][] */ 67,-96,10,-60,-51,55,54,-43,43,-32, 18,-63,48,64,-92,28,-55,-50,34,-50, 65,18,4,10,93,22,58,62,-27,-46, 35,-52,-37,-9,-24,-74,-82,-32,35,39, 3,-50,-42,-28,70,-64,2,35,-14,-90, 
  /* [2][0][][] */ -57,-41,19,56,25,-37,-56,-40,52,5, -18,10,16,-19,-62,-68,22,59,44,37, -45,38,-28,63,23,-41,-62,-7,30,8, -37,-44,-16,-50,83,-31,-70,12,-3,-1, 78,62,-40,-9,-5,102,51,-68,4,-70, 
  /* [2][1][][] */ -13,34,-49,40,-47,16,3,-65,79,78, 9,37,-58,36,-17,56,19,11,-35,-20, 19,-12,71,11,37,8,7,-24,-54,44, 34,15,47,11,32,-48,38,55,54,-47, -15,49,9,-29,-54,-9,31,52,-15,-57, 
  /* [2][2][][] */ -34,47,-11,7,-18,7,4,49,28,66, 10,25,-34,19,-68,32,24,9,14,24, -61,52,-54,52,0,15,43,27,61,46, 50,24,33,-3,-35,-19,6,-9,29,32, 33,-30,-22,-61,10,-40,-61,29,10,15, 
  /* [2][3][][] */ 33,47,71,-11,46,-37,24,20,-7,-17, 80,31,40,64,0,92,35,-75,84,38, -31,40,-33,-35,9,56,13,15,118,-2, -29,25,-6,74,-71,-3,-43,-62,25,56, -89,-2,12,-48,-78,-52,32,-79,-76,66, 
  /* [2][4][][] */ 15,-35,84,27,127,-30,-41,-70,57,-11, 75,-14,-55,32,-8,50,-46,-10,81,-48, -26,7,-57,10,-8,-24,17,20,39,7, -123,24,-10,54,-48,-15,31,-41,25,15, -59,-1,-7,41,-48,-26,-35,-94,-21,-10, 
  /* [3][0][][] */ -80,-85,-14,71,-60,-10,-36,79,26,54, 18,10,65,5,33,-90,52,-32,-51,-56, 72,27,8,-8,17,65,-51,27,-17,27, 104,-38,25,-65,61,81,16,14,-49,-19, -5,-113,57,64,70,25,37,4,-23,78, 
  /* [3][1][][] */ -124,-15,-34,58,65,58,27,77,60,67, 27,91,-8,-68,-40,8,1,33,28,61, -25,21,48,-24,64,2,40,12,-41,-116, 9,-77,-9,77,-6,24,27,-59,-5,22, -56,-81,-46,0,10,-52,-28,31,58,-58, 
  /* [3][2][][] */ -59,10,-26,110,-21,1,-60,-83,21,68, 27,32,2,-16,-77,6,-6,-2,20,16, -5,-38,-24,-86,44,2,42,101,11,1, 85,16,-49,2,102,2,-12,2,-45,-33, -33,-97,17,-113,-34,-39,-22,-98,-13,-8, 
  /* [3][3][][] */ 82,-79,15,2,-71,-21,-90,-47,-3,21, 60,9,-32,2,-17,25,-36,36,56,-7, 37,0,26,28,67,-61,-60,73,-27,49, -78,-12,32,25,6,-54,2,66,1,-6, -67,-48,-67,-67,2,60,-56,-54,-92,-24, 
  /* [3][4][][] */ -16,-82,20,-43,-63,-43,42,-7,76,-18, 40,127,34,-9,61,48,81,23,-6,-8, -38,9,90,97,99,-13,0,81,22,41, -33,-70,58,51,-45,-92,-89,-57,26,52, 100,-37,32,113,-59,-11,28,-33,-108,-94, 
  /* [4][0][][] */ -2,-43,2,18,-70,6,-71,44,-98,-86, 54,37,-61,54,-19,-65,-78,44,82,-47, -31,-25,-122,33,-102,-86,27,-64,-25,-84, -14,21,-8,75,-96,64,58,-42,-6,83, 46,10,72,-34,32,-81,71,98,70,-79, 
  /* [4][1][][] */ -55,-23,-13,-54,-109,-102,23,0,-22,-108, 46,-17,-122,-88,-67,0,-21,27,-82,16, -1,-52,-14,10,-67,12,60,-114,29,-17, 2,53,-20,-40,-77,35,63,22,16,38, -115,2,-69,-84,-42,-70,-111,-33,38,77, 
  /* [4][2][][] */ 37,27,38,-45,32,41,-37,-64,69,-3, -65,-47,-84,20,-48,-43,34,-39,-69,-64, -2,-78,65,20,-127,-93,-23,78,-44,-45, 15,-33,36,-104,49,-80,-119,-29,-30,-78, 39,-58,19,-43,-23,32,-101,-13,42,76, 
  /* [4][3][][] */ 48,-114,39,77,-29,-112,-20,-111,-63,-35, -5,14,-21,84,75,-37,22,28,-18,-12, 47,26,-8,-101,-5,-112,-11,64,47,-99, -65,30,-6,-8,-61,-38,-79,-6,-11,-54, -26,-45,-84,54,38,-39,-78,-7,-24,-50, 
  /* [4][4][][] */ -91,6,16,-50,-105,-86,25,31,64,-98, -14,46,-83,55,-48,-99,29,51,54,59, 13,70,-98,62,-45,-8,-6,76,-53,44, -58,-24,88,49,66,23,59,18,44,-5, -81,-108,43,-58,-68,53,44,-106,27,59, 
};
const TfArray<4, int> tensor_dimension8 = { 4, { 5,5,5,10 } };
const TfArray<5, float> quant8_scale = { 5, { 0.0013250301126390696, 0.0019188310252502561, 0.0024017954710870981, 0.0018853975925594568, 0.0012955275597050786, } };
const TfArray<5, int> quant8_zero = { 5, { 0,0,0,0,0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const TfArray<4, int> tensor_dimension9 = { 4, { 1,50,13,1 } };
const TfArray<1, float> quant9_scale = { 1, { 0.034759312868118286, } };
const TfArray<1, int> quant9_zero = { 1, { 7 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const TfArray<4, int> tensor_dimension10 = { 4, { 1,50,13,10 } };
const TfArray<1, float> quant10_scale = { 1, { 0.023246008902788162, } };
const TfArray<1, int> quant10_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const TfArray<4, int> tensor_dimension11 = { 4, { 1,25,7,10 } };
const TfArray<1, float> quant11_scale = { 1, { 0.023246008902788162, } };
const TfArray<1, int> quant11_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1,25,7,5 } };
const TfArray<1, float> quant12_scale = { 1, { 0.015910984948277473, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1,13,4,5 } };
const TfArray<1, float> quant13_scale = { 1, { 0.015910984948277473, } };
const TfArray<1, int> quant13_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<2, int> tensor_dimension14 = { 2, { 1,260 } };
const TfArray<1, float> quant14_scale = { 1, { 0.015910984948277473, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<2, int> tensor_dimension15 = { 2, { 1,2 } };
const TfArray<1, float> quant15_scale = { 1, { 0.0095610562711954117, } };
const TfArray<1, int> quant15_zero = { 1, { -59 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<2, int> tensor_dimension16 = { 2, { 1,2 } };
const TfArray<1, float> quant16_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant16_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,5 } };
const TfArray<1, int> outputs0 = { 1, { 9 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 9,7,2 } };
const TfArray<1, int> outputs1 = { 1, { 10 } };
const TfLitePoolParams opdata2 = { kTfLitePaddingSame, 2,2, 2,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs2 = { 1, { 10 } };
const TfArray<1, int> outputs2 = { 1, { 11 } };
const TfLiteConvParams opdata3 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs3 = { 3, { 11,8,3 } };
const TfArray<1, int> outputs3 = { 1, { 12 } };
const TfLitePoolParams opdata4 = { kTfLitePaddingSame, 2,2, 2,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs4 = { 1, { 12 } };
const TfArray<1, int> outputs4 = { 1, { 13 } };
const TfLiteReshapeParams opdata5 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs5 = { 2, { 13,1 } };
const TfArray<1, int> outputs5 = { 1, { 14 } };
const TfLiteFullyConnectedParams opdata6 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs6 = { 3, { 14,6,4 } };
const TfArray<1, int> outputs6 = { 1, { 15 } };
const TfLiteSoftmaxParams opdata7 = { 1 };
const TfArray<1, int> inputs7 = { 1, { 15 } };
const TfArray<1, int> outputs7 = { 1, { 16 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension0, 650, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 40, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant2))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 20, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant3))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 8, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant4))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 520, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 250, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data8, (TfLiteIntArray*)&tensor_dimension8, 1250, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 6512, (TfLiteIntArray*)&tensor_dimension9, 650, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension10, 6500, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 6512, (TfLiteIntArray*)&tensor_dimension11, 1750, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 875, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 880, (TfLiteIntArray*)&tensor_dimension13, 260, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 260, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 272, (TfLiteIntArray*)&tensor_dimension15, 2, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant15))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension16, 2, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant16))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_AVERAGE_POOL_2D, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_AVERAGE_POOL_2D, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs7, (TfLiteIntArray*)&outputs7, const_cast<void*>(static_cast<const void*>(&opdata7)), OP_SOFTMAX, },
};
static std::vector<void*> overflow_buffers;
static TfLiteStatus AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                                 size_t bytes, void** ptr) {
  if (current_location - bytes < tensor_boundary) {
    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    *ptr = malloc(bytes);
    if (*ptr == NULL) {
      printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return kTfLiteError;
    }
    overflow_buffers.push_back(*ptr);
    return kTfLiteOk;
  }

  current_location -= bytes;

  *ptr = current_location;
  return kTfLiteOk;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static std::vector<scratch_buffer_t> scratch_buffers;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  scratch_buffer_t b;
  b.bytes = bytes;

  TfLiteStatus s = AllocatePersistentBuffer(ctx, b.bytes, &b.ptr);
  if (s != kTfLiteOk) {
    return s;
  }

  scratch_buffers.push_back(b);

  *buffer_idx = scratch_buffers.size() - 1;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > static_cast<int>(scratch_buffers.size()) - 1) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}
} // namespace

  TfLiteStatus trained_model_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.tensors = tflTensors;
  ctx.tensors_size = 17;
  for(size_t i = 0; i < 17; ++i) {
    tflTensors[i].type = tensorData[i].type;
    tflTensors[i].is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    tflTensors[i].allocation_type = tensorData[i].allocation_type;
#else
    tflTensors[i].allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
    tflTensors[i].bytes = tensorData[i].bytes;
    tflTensors[i].dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    if(tflTensors[i].allocation_type == kTfLiteArenaRw){
      uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

     tflTensors[i].data.data =  start;
    }
    else{
       tflTensors[i].data.data = tensorData[i].data;
    }
#else
    tflTensors[i].data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
    tflTensors[i].quantization = tensorData[i].quantization;
    if (tflTensors[i].quantization.type == kTfLiteAffineQuantization) {
      TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
      tflTensors[i].params.scale = quant->scale->data[0];
      tflTensors[i].params.zero_point = quant->zero_point->data[0];
    }
    if (tflTensors[i].allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tflTensors[i].data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_RESHAPE] = *tflite::ops::micro::Register_RESHAPE();
  registrations[OP_CONV_2D] = *tflite::ops::micro::Register_CONV_2D();
  registrations[OP_AVERAGE_POOL_2D] = *tflite::ops::micro::Register_AVERAGE_POOL_2D();
  registrations[OP_FULLY_CONNECTED] = *tflite::ops::micro::Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = *tflite::ops::micro::Register_SOFTMAX();

  for(size_t i = 0; i < 8; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
    tflNodes[i].custom_initial_data = nullptr;
    tflNodes[i].custom_initial_data_size = 0;
    if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for(size_t i = 0; i < 8; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteTensor* trained_model_input(int index) {
  return &ctx.tensors[inTensorIndices[index]];
}

static const int outTensorIndices[] = {
  16, 
};
TfLiteTensor* trained_model_output(int index) {
  return &ctx.tensors[outTensorIndices[index]];
}

TfLiteStatus trained_model_invoke() {
  for(size_t i = 0; i < 8; ++i) {
    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus trained_model_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif
  scratch_buffers.clear();
  for (size_t ix = 0; ix < overflow_buffers.size(); ix++) {
    free(overflow_buffers[ix]);
  }
  overflow_buffers.clear();
  return kTfLiteOk;
}
